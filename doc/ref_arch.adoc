:data-uri:
:rhtlink: link:https://www.redhat.com[Red Hat]
:mwlaboverviewsetup: link:http://people.redhat.com/jbride/labsCommon/setup.html[Middleware Lab Overview and Set-up]
:brmsproduct: link:https://access.redhat.com/documentation/en-US/Red_Hat_JBoss_BRMS/[Red Hat JBoss BRMS 6 product]
:datagridproduct: link:https://access.redhat.com/documentation/en-US/Red_Hat_JBoss_Data_Grid/[Red Hat JBoss Data Grid product]
:eapproduct: link:https://access.redhat.com/documentation/en-US/JBoss_Enterprise_Application_Platform/[JBoss Enterprise Application Platform product]
:haceppreso: link:http://www.slideshare.net/DuncanDoyle/doyle-h-0945highavailablitycepwithredhatjbossbrms3[High Available Complex Event Processing presentation]
:hacepgitrepo: link:https://github.com/DuncanDoyle/RHSummit2014HaCepBrms[source code]

= Highly Available JBoss BRMS CEP

*Goal*
Configure a highly available JBoss BRMS CEP deployment topology

:numbered:

== Overview
This document proposes a solution of high availability for CEP engines and address some challenges when combining JBoss BRMS CEP with HA, like the following:

* Session for CEP are:
** Stateful, state must be persisted.
** Used by all Events, sessions are not partitioned by event type, user or session-id.
** Memory consumption, sessions can have days, due to the events correlation behavior.

== Credits
This project builds upon the outstanding contributions of Dunkin Doyle and the Red Hat BRMS engineering team.

In particular, Dunkin's {haceppreso} and {hacepgitrepo} have been highly leveraged.

== Pre-Requisites

The remainder of this documentation provides instructions for installation, configuration and execution of this reference architecture in Red Hat's Partner Demo System.
The following is a list of pre-requisites:

. OPENTLC-SSO credentials
+
`OPENTLC-SSO` user credentials are used to log into the Red Hat Partner Demo System (PDS).
If you do not currently have an `OPENTLC-SSO` userId, please email: `OPEN-program@redhat.com`.

. Familiarity with Partner Demo System
+
If you are not already familiar with Red Hat's `Partner Demo System`, please execute what is detailed in the {mwlaboverviewsetup} guide.
Doing so will ensure that you are proficient with the tooling and workflow needed to complete this reference architecture in an OpenShift Platform as a Service environment.

. Familiarity with {brmsproduct}
. Complex Event Processing
. Familiarity with {datagridproduct}
. Familiarity with {eapproduct}

== Architecture Components

=== UML Deployment Diagram

=== Data Model

===  Messaging Broker

====  Purpose
====  Hornetq vs Apache Kafka discussion
====  HA Hornetq


=== Event UUID Object

=== BPMS/CEP Nodes
==== JMS Topic Consumer
==== Psuedo Clock
==== Event Processing
**  cep nodes receive JMS message. JMS message contains a CEP event.
** CEP clock is advanced
** rule engine is fired
** create the command in the RHS
** add that to cache.

==== Hot-Rod client

=== JBoss Data Grid
==== Purpose
Purpose of JDG is to store the commands generated in the RHS to have idempotent behaviour when the engine restarts.
It's used to implement the replay executions.

==== JDG Library Mode Deployment Topology
==== JDG Replication Mode State Transfer

=== Command Object
Need to be identical so as to prevent duplicate commands.
Command ID is composed of:   rule package, rule name and event uuid

=== Command Dispatcher

=== Command Executor

In a case of recovery commands in the cache would be read again but discarded since they already are in the cache. This can be better checked by just checking the last ID in the cache and the ID from the durable topic which have been read again in the recovery process so no need to check all of them and discard.

== Procedure
* For the purposes of this documentation, the name _$REF_ARCH_HOME_ refers to the root directory of this reference architecture.

=== Creation of 2 instances of EAP6 in OSE + datagrid (they should be in cluster)
=== Configure security, jms topic and roles.
=== Configure producer to run in local student machine (build process)
=== When a node crashes it replay all commands until it gets updated.

== Steps to Reproduce the Environment

NOTE: The steps listed below are just to reproduce the environment with the solution working. Steps need to be polished and migrated to be OSE compliant.

Your system needs to be multi-homed. The provided startup scripts bind JBoss EAP to address 127.0.0.1, the CEP node 1 to 127.0.0.3 and the CEP node 2 to 127.0.0.4.



=== Clone this project

=== Configure and Start JBoss EAP-6.4 Hornetq Broker

 Download the `jboss-eap-6.3.0.zip` and `jboss-eap-6.3.3-patch.zip` from the *Red Hat Customer Support Portal* and place them in the `demo/installation_zips` directory.
* In the `demo` directory, run the `buildJBossEap-HaCepBrms-Demo-Environment.sh` script. This will setup JBoss EAP 6.3.3 in the `demo/target` directory.

NOTE: This last step will fail trying to connect the controller, but it will create the admin user/password and guest user/password. I solved doing all the steps manually as follows.

* After the execution of the `buildJBossEap-HaCepBrms-Demo-Environment.sh` script, run the `startJBossEAP.sh` script to start JBoss EAP. Open a new terminal move to `RHSummit2014HaCepBrms/demo/target/jboss-eap-6.3/bin`and connect to the controller manually by executing `./jboss-cli.sh -c`.
* In the prompt `[standalone@localhost:9999 /]` apply the patch by executing `patch apply /path/to/project/RHSummit2014HaCepBrms/demo/installation_zips/jboss-eap-6.3.3-patch.zip`. The return should be:

[source,json]
----
{
    "outcome" : "success",
    "response-headers" : {
        "operation-requires-restart" : true,
        "process-state" : "restart-required"
    }
}
----

* Now execute the command to create the Durable Topic:

-----
/subsystem=messaging/hornetq-server=default/jms-topic=EventTopic:add(entries=["topic/event", "java:jboss/exported/topic/event"])
-----

The return should be:

[source,json]
-----
{"outcome" => "success"}
-----

* The `guest` role must have the right permissions, so execute:

-----
/subsystem=messaging/hornetq-server=default/security-setting=#/role=guest:write-attribute(name=create-durable-queue, value=true)
-----

And then:

-----
/subsystem=messaging/hornetq-server=default/security-setting=#/role=guest:write-attribute(name=delete-durable-queue, value=true)
-----

=== Build project
. cd $LAB_HOME
. execute:
+
-----
mvn clean compile -s ~/.m2/jdg-offline-settings.xml
-----

=== Start CEP Nodes
. cd $LAB_HOME/RHSummitHaCepApp
. Start CEP node 1:
+
-----
mvn exec:java -s ~/.m2/jdg-offline-settings.xml
-----
. Start CEP node 2:
+
-----
mvn exec:java -s ~/.m2/jdg-offline-settings.xml -Drhsummit2014.hornetq.client.id=rhsummit2014-hq-client-2
-----

=== Start Event Producer Client

-----
mvn exec:java -s ~/.m2/jdg-offline-settings.xml
-----

* To test the replay behavior stop one of the CEP engines and start it again. The commands will be replied but not executed, all of them must be discarded.
